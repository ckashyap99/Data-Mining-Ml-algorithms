{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[very late]\n"
     ]
    }
   ],
   "source": [
    "###Question 1\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load the data from the observation table\n",
    "data = pd.DataFrame({\n",
    "    'Day': ['weekday', 'weekday', 'weekday', 'weekday', 'saturday', 'weekday', 'holiday', 'sunday', 'weekday', 'weekday', 'saturday', 'weekday', 'saturday', 'weekday', 'weekday', 'saturday', 'weekday', 'holiday', 'weekday', 'weekday'],\n",
    "    'Season': ['spring', 'winter', 'winter', 'winter', 'summer', 'autumn', 'summer', 'summer', 'winter', 'summer', 'spring', 'summer', 'winter', 'summer', 'winter', 'autumn', 'autumn', 'spring', 'spring', 'spring'],\n",
    "    'Wind': ['none', 'none', 'none', 'high', 'normal', 'normal', 'high', 'normal', 'high', 'none', 'high', 'high', 'normal', 'high', 'normal', 'high', 'none', 'normal', 'normal', 'normal'],\n",
    "    'Rain': ['none', 'slight', 'slight', 'heavy', 'none', 'none', 'slight', 'none', 'heavy', 'slight', 'heavy', 'slight', 'none', 'none', 'heavy', 'slight', 'heavy', 'slight', 'none', 'slight'],\n",
    "    'Class': ['on time', 'on time', 'on time', 'late', 'on time', 'very late', 'on time', 'on time', 'very late', 'on time', 'cancelled', 'on time', 'late', 'on time', 'very late', 'on time', 'on time', 'on time', 'on time', 'on time']\n",
    "})\n",
    "\n",
    "# Convert categorical variables to numerical values using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['Day', 'Season', 'Wind', 'Rain'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Create and fit the Naive Bayes classifier\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Define the case to predict\n",
    "case = pd.DataFrame({\n",
    "    'Day_weekday': [1],\n",
    "    'Day_saturday': [0],\n",
    "    'Day_sunday': [0],\n",
    "    'Day_holiday': [0],\n",
    "    'Season_spring': [0],\n",
    "    'Season_winter': [1],\n",
    "    'Season_summer': [0],\n",
    "    'Season_autumn': [0],\n",
    "    'Wind_none': [0],\n",
    "    'Wind_normal': [0],\n",
    "    'Wind_high': [1],\n",
    "    'Rain_none': [0],\n",
    "    'Rain_slight': [0],\n",
    "    'Rain_heavy': [1]\n",
    "})\n",
    "\n",
    "# Predict the class for the given case\n",
    "prediction = classifier.predict(case)\n",
    "\n",
    "# Print the predicted class\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "###Question 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Load the data from the Excel file\n",
    "data = pd.read_excel('data3.xlsx', header=None)\n",
    "\n",
    "# Split the data into the two classes\n",
    "c1_data = data.iloc[:100]\n",
    "c2_data = data.iloc[100:200]\n",
    "\n",
    "# Calculate the mean and covariance for each class\n",
    "c1_mean = np.mean(c1_data, axis=0)\n",
    "c1_cov = np.cov(c1_data.T)\n",
    "c2_mean = np.mean(c2_data, axis=0)\n",
    "c2_cov = np.cov(c2_data.T)\n",
    "\n",
    "# Construct the 2D Gaussian models for each class\n",
    "c1_model = multivariate_normal(c1_mean, c1_cov)\n",
    "c2_model = multivariate_normal(c2_mean, c2_cov)\n",
    "\n",
    "# Classify the remaining 20 points\n",
    "test_data = data.iloc[200:]\n",
    "predictions = []\n",
    "for index, row in test_data.iterrows():\n",
    "    c1_prob = c1_model.pdf(row)\n",
    "    c2_prob = c2_model.pdf(row)\n",
    "    if c1_prob > c2_prob:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(2)\n",
    "\n",
    "# Calculate the accuracy, specificity, and sensitivity of the classifier\n",
    "true_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "c1_true = np.sum(np.array(predictions)[:10] == 1)\n",
    "c1_false = np.sum(np.array(predictions)[:10] == 2)\n",
    "c2_true = np.sum(np.array(predictions)[10:] == 2)\n",
    "c2_false = np.sum(np.array(predictions)[10:] == 1)\n",
    "specificity = c2_true / (c2_true + c2_false)\n",
    "sensitivity = c1_true / (c1_true + c1_false)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Specificity: 1.0\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "###Question 3\n",
    "\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# Classify the remaining 20 points using Mahalanobis distance\n",
    "test_data = data.iloc[200:]\n",
    "predictions = []\n",
    "for index, row in test_data.iterrows():\n",
    "    c1_distance = mahalanobis(row, c1_mean, np.linalg.inv(c1_cov))\n",
    "    c2_distance = mahalanobis(row, c2_mean, np.linalg.inv(c2_cov))\n",
    "    if c1_distance < c2_distance:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(2)\n",
    "\n",
    "# Calculate the accuracy, specificity, and sensitivity of the classifier\n",
    "true_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "c1_true = np.sum(np.array(predictions)[:10] == 1)\n",
    "c1_false = np.sum(np.array(predictions)[:10] == 2)\n",
    "c2_true = np.sum(np.array(predictions)[10:] == 2)\n",
    "c2_false = np.sum(np.array(predictions)[10:] == 1)\n",
    "specificity = c2_true / (c2_true + c2_false)\n",
    "sensitivity = c1_true / (c1_true + c1_false)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (k=1, Euclidean): 1.0\n",
      "Accuracy (k=3, Euclidean): 1.0\n"
     ]
    }
   ],
   "source": [
    "###Question 4\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the training set and labels\n",
    "X_train = np.vstack([c1_data, c2_data])\n",
    "y_train = np.hstack([np.ones(100), np.ones(100) * 2])\n",
    "\n",
    "# Create the test set\n",
    "X_test = data.iloc[200:]\n",
    "\n",
    "# Create the k-NN classifier with k=1 and Euclidean distance measure\n",
    "knn_1 = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "knn_1.fit(X_train, y_train)\n",
    "predictions_1 = knn_1.predict(X_test)\n",
    "\n",
    "# Create the k-NN classifier with k=3 and Euclidean distance measure\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_3.fit(X_train, y_train)\n",
    "predictions_3 = knn_3.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifiers\n",
    "true_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "accuracy_1 = np.mean(predictions_1 == true_labels)\n",
    "accuracy_3 = np.mean(predictions_3 == true_labels)\n",
    "\n",
    "print(\"Accuracy (k=1, Euclidean):\", accuracy_1)\n",
    "print(\"Accuracy (k=3, Euclidean):\", accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "Accuracy Manhattan: 1.0\n",
      "Accuracy Cosine: 0.75\n",
      "Accuracy Chebyshev: 1.0\n"
     ]
    }
   ],
   "source": [
    "knn_manhattan = KNeighborsClassifier(n_neighbors=1, metric='manhattan')\n",
    "knn_manhattan.fit(X_train, y_train)\n",
    "predictions_manhattan = knn_manhattan.predict(X_test)\n",
    "print(predictions_manhattan)\n",
    "\n",
    "knn_cosine = KNeighborsClassifier(n_neighbors=1, metric='cosine')\n",
    "knn_cosine.fit(X_train, y_train)\n",
    "predictions_cosine = knn_cosine.predict(X_test)\n",
    "print(predictions_cosine)\n",
    "\n",
    "knn_chebyshev = KNeighborsClassifier(n_neighbors=1, metric='chebyshev')\n",
    "knn_chebyshev.fit(X_train, y_train)\n",
    "predictions_chebyshev = knn_chebyshev.predict(X_test)\n",
    "print(predictions_chebyshev)\n",
    "\n",
    "true_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "accuracy_manhattan = np.mean(predictions_manhattan == true_labels)\n",
    "accuracy_cosine = np.mean(predictions_cosine == true_labels)\n",
    "accuracy_chebyshev = np.mean(predictions_chebyshev == true_labels)\n",
    "\n",
    "print(\"Accuracy Manhattan:\", accuracy_manhattan)\n",
    "print(\"Accuracy Cosine:\", accuracy_cosine)\n",
    "print(\"Accuracy Chebyshev:\", accuracy_chebyshev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (LDA): 1.0\n"
     ]
    }
   ],
   "source": [
    "###Question 5\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Create the LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "predictions_lda = lda.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "true_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "accuracy_lda = np.mean(predictions_lda == true_labels)\n",
    "\n",
    "print(\"Accuracy (LDA):\", accuracy_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Naive Bayes): 1.0\n"
     ]
    }
   ],
   "source": [
    "###Question 6\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create the Naive Bayes classifier\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "true_labels = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "accuracy_nb = np.mean(predictions_nb == true_labels)\n",
    "\n",
    "print(\"Accuracy (Naive Bayes):\", accuracy_nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
